{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-A3RFpmWISto",
    "outputId": "d43f95d7-068f-4996-9e31-b7dfaff95f6f"
   },
   "outputs": [],
   "source": [
    "# from google.colab import userdata\n",
    "\n",
    "# # Clone the entire repo.\n",
    "# username = 'emilioapontea'\n",
    "# token = userdata.get(\"token\")\n",
    "# repo_name = 'ML-Team-38'\n",
    "\n",
    "# !git clone https://{username}:{token}@github.com/{username}/{repo_name}.git\n",
    "\n",
    "\n",
    "# %cd {repo_name}\n",
    "# !git pull\n",
    "# !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_rjMxaI8UTtg",
    "outputId": "3ddaba7d-33c0-492e-ad13-bd35a1d51b75"
   },
   "outputs": [],
   "source": [
    "# %cd ML-Team-38\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "x7U0uS87IHP7"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skimage'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tawsi\\OneDrive\\Desktop\\school\\ML-Team-38\\test.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tawsi/OneDrive/Desktop/school/ML-Team-38/test.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/tawsi/OneDrive/Desktop/school/ML-Team-38/test.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tawsi/OneDrive/Desktop/school/ML-Team-38/test.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tawsi/OneDrive/Desktop/school/ML-Team-38/test.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtransforms\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tawsi\\OneDrive\\Desktop\\school\\ML-Team-38\\preprocessing.py:7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtransforms\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mskimage\u001b[39;00m \u001b[39mimport\u001b[39;00m feature\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mPIL\u001b[39;00m \u001b[39mimport\u001b[39;00m Image\n\u001b[0;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mopen_image\u001b[39m(filepath: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Image:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'skimage'"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "from preprocessing import *\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "E74gi4k-IHP9"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "num_classes = 10\n",
    "dataset = ImageFolder(root=\"./split_dataset/train\", transform=transform)\n",
    "\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kdPzccggIHP9",
    "outputId": "5a749898-57e9-413c-c7b6-b82a855b2bae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/victorguyard/miniconda3/envs/ml_project/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/victorguyard/miniconda3/envs/ml_project/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.resnet18(pretrained=True) # RESNET18\n",
    "# model = torchvision.models.resnet50(pretrained=True) # RESNET50\n",
    "# model = torchvision.models.vgg16(pretrained=True) #VGG16\n",
    "# model =  torchvision.models.inception_v3(pretrained=True) # INCEPTION V3\n",
    "in_features = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(in_features, num_classes)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "1vUUDuvjIHP-"
   },
   "outputs": [],
   "source": [
    "numEpochs = 3\n",
    "\n",
    "def testAccuracy(dataPath, model):\n",
    "  testset = ImageFolder(root=dataPath, transform=transform)\n",
    "  testloader = torch.utils.data.DataLoader(testset, batch_size=10,\n",
    "                                         shuffle=False)\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  with torch.no_grad():\n",
    "      for data in testloader:\n",
    "          images, labels = data\n",
    "          outputs = model(images)\n",
    "          _, predicted = torch.max(outputs.data, 1)\n",
    "          total += labels.size(0)\n",
    "          correct += (predicted == labels).sum().item()\n",
    "\n",
    "  print(f'Accuracy of the network on the images {100 * correct / total} on {dataPath}')\n",
    "  print('Accuracy of the network on the images: %d %%' % (\n",
    "      100 * correct / total))\n",
    "\n",
    "test_acc_history = []\n",
    "val_acc_history = []\n",
    "\n",
    "def trainModel():\n",
    "    i = 0\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    for epoch in range(numEpochs):\n",
    "        for images, labels in dataloader:\n",
    "            images.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            print(f\"Training: {epoch} {i}\")\n",
    "            i += 1\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        print(f\"Evaluating on Train: {epoch}\")\n",
    "        test_acc_history.append(testAccuracy(\"./split_dataset/train\", model))\n",
    "        print(f\"Evaluating on Val: {epoch}\")\n",
    "        val_acc_history.append(testAccuracy(\"./split_dataset/val\", model))\n",
    "        model.train()\n",
    "\n",
    "\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{numEpochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yuVrL2BWIHP-",
    "outputId": "ed4e1375-d276-4154-b2c9-366c75450e5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 0 0\n",
      "Training: 0 1\n",
      "Training: 0 2\n",
      "Training: 0 3\n",
      "Training: 0 4\n",
      "Training: 0 5\n",
      "Training: 0 6\n",
      "Training: 0 7\n",
      "Training: 0 8\n",
      "Training: 0 9\n",
      "Training: 0 10\n",
      "Training: 0 11\n",
      "Training: 0 12\n"
     ]
    }
   ],
   "source": [
    "model = trainModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gyThYEEqIHP-",
    "outputId": "71984cc9-439f-4240-9f5a-4a874fb9a7a8"
   },
   "outputs": [],
   "source": [
    "dataiter = iter(dataloader)\n",
    "images, labels = dataiter.__next__()\n",
    "\n",
    "\n",
    "classes = ('0', '1', '2', '3',\n",
    "           '4', '5', '6', '7', '8', '9')\n",
    "\n",
    "outputs = model(images)\n",
    "\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%s' % classes[predicted[j]]\n",
    "                              for j in range(4)))\n",
    "# print images\n",
    "plt.imshow(torchvision.utils.make_grid(images).permute(1, 2, 0))\n",
    "print('GroundTruth: ', ' '.join('%s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "goVOuSTNIHP-"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './models/resnet-18.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vis_utils import *\n",
    "\n",
    "plot_acc_history(train_acc_history, val_acc_history) and\n",
    "plot_acc_history(test_acc_history, test_val_history)\n",
    "\n",
    "generate_and_plot_confusion_matrix("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
