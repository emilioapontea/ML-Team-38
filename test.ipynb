{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-A3RFpmWISto",
        "outputId": "d43f95d7-068f-4996-9e31-b7dfaff95f6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'ML-Team-38' already exists and is not an empty directory.\n",
            "/content/ML-Team-38\n",
            "remote: Enumerating objects: 15, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 12 (delta 6), reused 9 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (12/12), 1.73 KiB | 196.00 KiB/s, done.\n",
            "From https://github.com/emilioapontea/ML-Team-38\n",
            "   94ede36..7b0b1f0  main       -> origin/main\n",
            "Updating 94ede36..7b0b1f0\n",
            "Fast-forward\n",
            " .gitignore                                           |  1 \u001b[32m+\u001b[m\n",
            " ExamplePuma.json => scrapingTools/ExamplePuma.json   |  0\n",
            " countImgs.py => scrapingTools/countImgs.py           |  0\n",
            " downloadAdidas.py => scrapingTools/downloadAdidas.py |  0\n",
            " downloadAsics.py => scrapingTools/downloadAsics.py   |  0\n",
            " downloadNike.py => scrapingTools/downloadNike.py     |  0\n",
            " downloadPuma.py => scrapingTools/downloadPuma.py     |  0\n",
            " downloadReebok.py => scrapingTools/downloadReebok.py |  0\n",
            " example.html => scrapingTools/example.html           |  0\n",
            " jsonFixer.py => scrapingTools/jsonFixer.py           |  0\n",
            " scrapeAdidas.py => scrapingTools/scrapeAdidas.py     |  0\n",
            " scrapeAsics.py => scrapingTools/scrapeAsics.py       |  0\n",
            " scrapeNike.py => scrapingTools/scrapeNike.py         |  0\n",
            " scrapePuma.py => scrapingTools/scrapePuma.py         |  0\n",
            " scrapeReebok.py => scrapingTools/scrapeReebok.py     |  0\n",
            " test.ipynb                                           | 21 \u001b[32m+++++++++++++\u001b[m\u001b[31m--------\u001b[m\n",
            " 16 files changed, 14 insertions(+), 8 deletions(-)\n",
            " rename ExamplePuma.json => scrapingTools/ExamplePuma.json (100%)\n",
            " rename countImgs.py => scrapingTools/countImgs.py (100%)\n",
            " rename downloadAdidas.py => scrapingTools/downloadAdidas.py (100%)\n",
            " rename downloadAsics.py => scrapingTools/downloadAsics.py (100%)\n",
            " rename downloadNike.py => scrapingTools/downloadNike.py (100%)\n",
            " rename downloadPuma.py => scrapingTools/downloadPuma.py (100%)\n",
            " rename downloadReebok.py => scrapingTools/downloadReebok.py (100%)\n",
            " rename example.html => scrapingTools/example.html (100%)\n",
            " rename jsonFixer.py => scrapingTools/jsonFixer.py (100%)\n",
            " rename scrapeAdidas.py => scrapingTools/scrapeAdidas.py (100%)\n",
            " rename scrapeAsics.py => scrapingTools/scrapeAsics.py (100%)\n",
            " rename scrapeNike.py => scrapingTools/scrapeNike.py (100%)\n",
            " rename scrapePuma.py => scrapingTools/scrapePuma.py (100%)\n",
            " rename scrapeReebok.py => scrapingTools/scrapeReebok.py (100%)\n",
            "adidasStuff  environment.yml  models\t\t__pycache__  scrapedData    split_dataset  utils.py\n",
            "dataset      imageVerify.py   preprocessing.py\tREADME.md    scrapingTools  test.ipynb\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "# Clone the entire repo.\n",
        "username = 'emilioapontea'\n",
        "token = userdata.get(\"token\")\n",
        "repo_name = 'ML-Team-38'\n",
        "\n",
        "!git clone https://{username}:{token}@github.com/{username}/{repo_name}.git\n",
        "\n",
        "\n",
        "%cd {repo_name}\n",
        "!git pull\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rjMxaI8UTtg",
        "outputId": "3ddaba7d-33c0-492e-ad13-bd35a1d51b75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'ML-Team-38'\n",
            "/content/ML-Team-38\n"
          ]
        }
      ],
      "source": [
        "%cd ML-Team-38\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "x7U0uS87IHP7"
      },
      "outputs": [],
      "source": [
        "from utils import *\n",
        "from preprocessing import *\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
        "from torchvision.datasets import ImageFolder\n",
        "from skimage import feature\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "E74gi4k-IHP9"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "            [\n",
        "                transforms.Resize((224, 224)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(\n",
        "                    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "num_classes = 10\n",
        "dataset = ImageFolder(root=\"./split_dataset/train\", transform=transform)\n",
        "\n",
        "# Create a subset of first 100 images\n",
        "indices = list(range(500))\n",
        "subset = Subset(dataset, indices)\n",
        "\n",
        "dataloader = DataLoader(subset, batch_size=64, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdPzccggIHP9",
        "outputId": "5a749898-57e9-413c-c7b6-b82a855b2bae"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/tawsifkamal/opt/anaconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/Users/tawsifkamal/opt/anaconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "# model = torchvision.models.resnet18(pretrained=True)\n",
        "model = torchvision.models.resnet50(pretrained=True) # RESNET50\n",
        "# model = torchvision.models.vgg16(pretrained=True) #VGG16\n",
        "# model =  torchvision.models.inception_v3(pretrained=True) # INCEPTION V3\n",
        "in_features = model.fc.in_features\n",
        "model.fc = torch.nn.Linear(in_features, num_classes)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1vUUDuvjIHP-"
      },
      "outputs": [],
      "source": [
        "numEpochs = 3\n",
        "\n",
        "def testAccuracy(dataPath, model):\n",
        "  testset = ImageFolder(root=dataPath, transform=transform)\n",
        "  testloader = torch.utils.data.DataLoader(testset, batch_size=10,\n",
        "                                         shuffle=False)\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "      for data in testloader:\n",
        "          images, labels = data\n",
        "          outputs = model(images)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print(f'Accuracy of the network on the images {100 * correct / total} on {dataPath}')\n",
        "  print('Accuracy of the network on the images: %d %%' % (\n",
        "      100 * correct / total))\n",
        "\n",
        "def trainModel():\n",
        "    i = 0\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    for epoch in range(numEpochs):\n",
        "        for images, labels in dataloader:\n",
        "            images.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            print(f\"Training: {epoch} {i}\")\n",
        "            i += 1\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        print(f\"Evaluating on Train: {epoch}\")\n",
        "        testAccuracy(\"./split_dataset/train\", model)\n",
        "        print(f\"Evaluating on Val: {epoch}\")\n",
        "        testAccuracy(\"./split_dataset/val\", model)\n",
        "        model.train()\n",
        "\n",
        "\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{numEpochs}], Loss: {loss.item():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuVrL2BWIHP-",
        "outputId": "ed4e1375-d276-4154-b2c9-366c75450e5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training: 0 0\n",
            "Training: 0 1\n",
            "Training: 0 2\n",
            "Training: 0 3\n",
            "Training: 0 4\n",
            "Training: 0 5\n",
            "Training: 0 6\n",
            "Training: 0 7\n",
            "Evaluating on Train: 0\n"
          ]
        }
      ],
      "source": [
        "trainModel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyThYEEqIHP-",
        "outputId": "71984cc9-439f-4240-9f5a-4a874fb9a7a8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted:  4 2 0 2\n",
            "GroundTruth:  0 0 0 0\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "\n",
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.__next__()\n",
        "\n",
        "\n",
        "classes = ('0', '1', '2', '3',\n",
        "           '4', '5', '6', '7', '8', '9')\n",
        "\n",
        "outputs = model(images)\n",
        "\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join('%s' % classes[predicted[j]]\n",
        "                              for j in range(4)))\n",
        "# print images\n",
        "plt.imshow(torchvision.utils.make_grid(images).permute(1, 2, 0))\n",
        "print('GroundTruth: ', ' '.join('%s' % classes[labels[j]] for j in range(4)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "goVOuSTNIHP-"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), './models/resnet.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CTONEYoIHP-",
        "outputId": "65684fae-6e59-4c85-e4dc-205f5c3aad3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test images: 21 %\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VOwifi2IHP_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from typing import Tuple\n",
        "\n",
        "# Assuming 'load_imagepaths_with_labels' loads image paths and corresponding labels\n",
        "# and 'open_image' opens the image from a given path\n",
        "\n",
        "def split_images(src_folder: str, dst_folder: str, p: float = 0.2) -> Tuple[int, int]:\n",
        "    img_paths = load_imagepaths_with_labels(src_folder)  # This should return a list of tuples\n",
        "    val_count = 0\n",
        "    train_count = 0\n",
        "    for (path, label) in img_paths:\n",
        "        r = np.random.uniform()\n",
        "        img = open_image(path)\n",
        "        # Choose the directory based on the random number\n",
        "        subdir = \"val\" if r < p else \"train\"\n",
        "        # Use the label as the directory name\n",
        "        label_dir = os.path.join(dst_folder, subdir, str(label))\n",
        "        os.makedirs(label_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
        "        # Extract the filename from the path\n",
        "        filename = os.path.basename(path)\n",
        "        # Save the image in the directory named after the label\n",
        "        img.save(os.path.join(label_dir, filename))\n",
        "        # Increment the appropriate counter\n",
        "        if subdir == \"val\":\n",
        "            val_count += 1\n",
        "        else:\n",
        "            train_count += 1\n",
        "    return val_count, train_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZC38fXnBIHP_",
        "outputId": "6ed5a8e1-574f-4b02-9615-9d51dd86464b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/tawsifkamal/opt/anaconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/Users/tawsifkamal/opt/anaconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "class CustomModel(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        root_path,\n",
        "        num_classes=2,\n",
        "        batch_size=32,\n",
        "        num_epochs=10,\n",
        "        learning_rate=0.001,\n",
        "    ):\n",
        "        super(CustomModel, self).__init__()\n",
        "        self.root_path = root_path\n",
        "        self.num_classes = num_classes\n",
        "        self.batch_size = batch_size\n",
        "        self.num_epochs = num_epochs\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        self.transform = transforms.Compose(\n",
        "            [\n",
        "                transforms.Resize((224, 224)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(\n",
        "                    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.dataset = ImageFolder(root=self.root_path, transform=self.transform)\n",
        "        self.dataloader = DataLoader(\n",
        "            self.dataset, batch_size=self.batch_size, shuffle=True\n",
        "        )\n",
        "\n",
        "        self.model = torchvision.models.resnet18(pretrained=True)\n",
        "        in_features = self.model.fc.in_features\n",
        "        self.model.fc = nn.Linear(in_features, self.num_classes)\n",
        "\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
        "\n",
        "    def trainModel(self):\n",
        "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        for epoch in range(self.num_epochs):\n",
        "            for images, labels in self.dataloader:\n",
        "                images.to(device)\n",
        "                self.optimizer.zero_grad()\n",
        "                outputs = self.model(images)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "            print(f\"Epoch [{epoch+1}/{self.num_epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "    def saveModel(self, save_path):\n",
        "        torch.save(self.model.state_dict(), save_path)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model = CustomModel(\n",
        "        root_path=\"./split_dataset/train\", num_classes=10, batch_size=512, num_epochs=1\n",
        "    )\n",
        "    model.trainModel()\n",
        "    model.saveModel(\"model.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewYlpwNRIHP_"
      },
      "source": [
        "torch.__version__"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
